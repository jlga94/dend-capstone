{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The project consists in develop a Fact Table with the data sources provided by the default project. The technologies involved were Pandas, Spark, Fbprohet and Matplotlib.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:fbprophet:Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_data = json.load(open('utils.json','r'))\n",
    "us_state_code = util_data['us_state_code']\n",
    "us_code_state = {v: k for k, v in us_state_code.items()}\n",
    "city_codes = util_data['city_codes']\n",
    "immigration_codes = util_data['immigration_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(spark)\n",
    "sqlContext.setConf(\"spark.sql.autoBroadcastJoinThreshold\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "state_codeUDF=udf(lambda x: us_state_code[x],StringType())\n",
    "code_stateUDF=udf(lambda x: us_code_state[x],StringType())\n",
    "city_codeUDF=udf(lambda x:city_codes[x],StringType())\n",
    "country_codeUDF=udf(lambda x: immigration_codes[x],StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "This project will pull data from all sources and create fact and dimension tables to show movement of immigration.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included?\n",
    "* I94 Immigration Data: comes from the US National Tourism and Trade Office and includes details on incoming immigrants and their ports of entry.\n",
    "* World Temperature Data: comes from kaggle and includes data on temperature changes in the U.S. since 1850.\n",
    "* U.S. City Demographic Data: comes from OpenSoft and includes data by city, state, age, population, veteran status and race.\n",
    "* Airport Code Table: comes from datahub.io and includes airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_airport = pd.read_csv(\"airport-codes_csv.csv\")\n",
    "df_demographics = pd.read_csv(\"us-cities-demographics.csv\",sep=';')\n",
    "df_temperature = pd.read_csv(\"GlobalLandTemperaturesByState.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "import datetime\n",
    "df_temperature['dt'] = pd.to_datetime(df_temperature['dt'])\n",
    "df_temperature['year'] = df_temperature['dt'].dt.year\n",
    "df_temperature['month'] = df_temperature['dt'].dt.month\n",
    "df_temperature['y'] = df_temperature['AverageTemperature']\n",
    "df_temperature['ds'] = df_temperature['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_temperature = df_temperature[(df_temperature[\"Country\"]==\"United States\")&(df_temperature['year'] > 1900)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_temperature['state_code'] = us_df_temperature.apply(lambda row: us_state_code[row[\"State\"]],axis=1)\n",
    "us_df_temperature = us_df_temperature[['dt','AverageTemperature','State','Country','year','month','state_code','y','ds']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_temperature.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_temperature_df = us_df_temperature[(us_df_temperature[\"state_code\"]==\"AL\")&(df_temperature['year'] > 2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_temperature_df['ds'] = alabama_temperature_df['dt']\n",
    "alabama_temperature_df['y'] = alabama_temperature_df['AverageTemperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_temperature_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_model = Prophet(interval_width=0.95)\n",
    "temperature_model.fit(alabama_temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_forecast = temperature_model.make_future_dataframe(periods=50, freq='MS')\n",
    "temperature_forecast = temperature_model.predict(temperature_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "temperature_model.plot(temperature_forecast, xlabel = 'Date', ylabel = 'AverageTemperature')\n",
    "plt.title('Date AverageTemperature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temperature_prediction(df):\n",
    "    temperature_model = Prophet(interval_width=0.95)\n",
    "    temperature_model.fit(df)\n",
    "    temperature_forecast = temperature_model.make_future_dataframe(periods=50, freq='MS')\n",
    "    temperature_forecast = temperature_model.predict(temperature_forecast)\n",
    "    temperature_forecast['year'] = temperature_forecast['ds'].dt.year\n",
    "    temperature_forecast['month'] = temperature_forecast['ds'].dt.month\n",
    "    temperature_forecast['AverageTemperature'] = temperature_forecast['yhat']\n",
    "    return temperature_forecast[['year','month','AverageTemperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_temperature_pred_df = pd.DataFrame(columns=['year','month','AverageTemperature','state_code','state','country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_code,state in us_code_state.items():\n",
    "    print(state_code,state)\n",
    "    try:\n",
    "        df = us_df_temperature[us_df_temperature[\"state_code\"]==state_code].copy()\n",
    "        df = get_temperature_prediction(df)\n",
    "        df = df[df['year'] > 2010]\n",
    "        df['state_code'] = state_code\n",
    "        df['state'] = state\n",
    "        df['country'] = 'United States'\n",
    "        us_temperature_pred_df = us_temperature_pred_df.append(df,ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_temperature_pred_df[us_temperature_pred_df['year'] == 2016].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_temperature_pred_df.to_csv(\"us_temperature.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immigration Data by State with Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
    "fname = '../18-83510-I94-Data-2016/i94_{}16_sub.sas7bdat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    filename = fname.format(month)\n",
    "    print(filename)\n",
    "    immigrationDF = spark.read.format('com.github.saurfang.sas.spark').load(filename)\n",
    "    \n",
    "    immigrationMonthDF=immigrationDF.filter(immigrationDF.i94addr.isNotNull())\\\n",
    "    .filter(immigrationDF.i94res.isNotNull())\\\n",
    "    .filter(col(\"i94addr\").isin(list(us_code_state.keys())))\\\n",
    "    .filter(col(\"i94port\").isin(list(city_codes.keys())))\\\n",
    "    .withColumn(\"i94res\",col(\"i94res\").cast(\"integer\").cast(\"string\"))\\\n",
    "    .withColumn(\"origin_country\",country_codeUDF(col(\"i94res\")))\\\n",
    "    .withColumn(\"State\",code_stateUDF(col(\"i94addr\")))\\\n",
    "    .withColumn(\"id\",col(\"cicid\").cast(\"integer\"))\\\n",
    "    .withColumn(\"state_code\",col(\"i94addr\"))\\\n",
    "    .withColumn(\"city_code\",col(\"i94port\"))\\\n",
    "    .withColumn(\"year\",col(\"i94yr\").cast(\"integer\"))\\\n",
    "    .withColumn(\"month\",col(\"i94mon\").cast(\"integer\"))\\\n",
    "    .withColumn(\"city\",city_codeUDF(col(\"i94port\")))\n",
    "                                  \n",
    "    immigrationMonthDF.select('id','year','month','origin_country','city_code','city','state_code','State').write.mode('append').parquet('immigration_data')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.S. Demographic Data by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.loc[df_demographics[\"Race\"] == \"American Indian and Alaska Native\",\"Race\"] = \"Native\"\n",
    "df_demographics.loc[df_demographics[\"Race\"] == \"Black or African-American\",\"Race\"] = \"Afroamerican\"\n",
    "df_demographics.loc[df_demographics[\"Race\"] == \"Hispanic or Latino\",\"Race\"] = \"Latino\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_demographics_avg_df = df_demographics.groupby(['State','State Code','Race'])['Median Age'].mean()\n",
    "us_demographics_sum_df = df_demographics.groupby(['State','State Code','Race'])['Total Population','Count','Male Population','Female Population','Number of Veterans','Foreign-born'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_demographics_df = pd.concat([us_demographics_sum_df,us_demographics_avg_df],axis=1)\n",
    "us_demographics_df.reset_index(inplace=True)\n",
    "us_demographics_df[\"state_code\"] = us_demographics_df[\"State Code\"]\n",
    "us_demographics_df[\"median_age\"] = us_demographics_df[\"Median Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_code in us_code_state:\n",
    "    print(state_code)\n",
    "    df = us_demographics_df.loc[us_demographics_df['state_code'] == state_code]\n",
    "    total_population = df['Total Population'].max()\n",
    "    male_population = df['Male Population'].max()\n",
    "    female_population = df['Female Population'].max()\n",
    "    veterans_population = df['Number of Veterans'].max()\n",
    "    foreign_population = df['Foreign-born'].max()\n",
    "    median_age = df['median_age'].max()\n",
    "    \n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'Total Population'] = total_population\n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'Male Population'] = male_population\n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'Female Population'] = female_population\n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'Number of Veterans'] = veterans_population\n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'Foreign-born'] = foreign_population\n",
    "    us_demographics_df.loc[us_demographics_df['state_code'] == state_code,'median_age'] = median_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_demographics_df[\"percentage_male\"] = us_demographics_df.apply(lambda row: float(row[\"Male Population\"]/row[\"Total Population\"])*100.0,axis=1)\n",
    "us_demographics_df[\"percentage_female\"] = us_demographics_df.apply(lambda row: float(row[\"Female Population\"]/row[\"Total Population\"])*100.0,axis=1)\n",
    "us_demographics_df[\"percentage_veterans\"] = us_demographics_df.apply(lambda row: float(row[\"Number of Veterans\"]/row[\"Total Population\"])*100.0,axis=1)\n",
    "us_demographics_df[\"percentage_foreign_born\"] = us_demographics_df.apply(lambda row: float(row[\"Foreign-born\"]/row[\"Total Population\"])*100.0,axis=1)\n",
    "us_demographics_df[\"percentage_race\"] = us_demographics_df.apply(lambda row: float(row[\"Count\"]/row[\"Total Population\"])*100.0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_demographics = pd.pivot_table(us_demographics_df,values='percentage_race',index=[\"State\",\"state_code\",\"median_age\",\"percentage_male\",\"percentage_female\",\"percentage_veterans\",\"percentage_foreign_born\"],columns=[\"Race\"], aggfunc=np.mean, fill_value=0)\n",
    "us_df_demographics = pd.DataFrame(us_df_demographics.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_demographics.to_csv(\"us_demographics.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U.S. Airport Data by State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_airport = df_airport[df_airport[\"iso_country\"]==\"US\"]\n",
    "us_df_airport = us_df_airport[(us_df_airport[\"type\"]==\"small_airport\")|(us_df_airport[\"type\"]==\"medium_airport\")|(us_df_airport[\"type\"]==\"large_airport\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_airport[\"elevation_ft\"] = us_df_airport.apply(lambda row: float(row[\"elevation_ft\"]),axis=1)\n",
    "us_df_airport[\"state_code\"] = us_df_airport.apply(lambda row: row[\"iso_region\"].split(\"-\")[-1],axis=1)\n",
    "us_df_airport[\"x_coordinate\"] = us_df_airport.apply(lambda row: float(row[\"coordinates\"].split(\",\")[0]),axis=1)\n",
    "us_df_airport[\"y_coordinate\"] = us_df_airport.apply(lambda row: float(row[\"coordinates\"].split(\",\")[-1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_airport[\"country\"] = us_df_airport[\"iso_country\"]\n",
    "us_df_airport[\"city_code\"] = us_df_airport[\"local_code\"]\n",
    "us_df_airport = us_df_airport[[\"ident\",\"type\",\"name\",\"elevation_ft\",\"country\",\"state_code\",\"city_code\",\"municipality\",\"x_coordinate\",\"y_coordinate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df_airport.to_csv(\"us_airports.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatureDF = spark.read.csv(\"us_temperature.csv\",header=True)\n",
    "demographicsDF = spark.read.csv(\"us_demographics.csv\",header=True)\n",
    "airportsDF = spark.read.csv(\"us_airports.csv\",header=True)\n",
    "immigrationDF = spark.read.parquet(\"immigration_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigrationDF = immigrationDF.filter(col(\"month\")<lit(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dimension tables\n",
    "temperatureDF.createOrReplaceTempView(\"temperature\")\n",
    "immigrationDF.createOrReplaceTempView(\"immigration\")\n",
    "demographicsDF.createOrReplaceTempView(\"demographics\")\n",
    "airportsDF.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16895557"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrationDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        immig.year,\n",
    "        immig.month,\n",
    "        immig.origin_country,\n",
    "        immig.State,\n",
    "        immig.state_code,\n",
    "        COUNT(immig.state_code) as number_immigrants,\n",
    "        temp.AverageTemperature as avg_temperature,\n",
    "        demo.median_age,\n",
    "        demo.percentage_male,\n",
    "        demo.percentage_female,\n",
    "        demo.percentage_veterans,\n",
    "        demo.percentage_foreign_born,\n",
    "        demo.Afroamerican as percentage_afroamerican,\n",
    "        demo.Asian as percentage_asian,\n",
    "        demo.Latino as percentage_latino,\n",
    "        demo.Native as percentage_native,\n",
    "        demo.White as percentage_white,\n",
    "        air.name as airport_name,\n",
    "        air.x_coordinate,\n",
    "        air.y_coordinate\n",
    "    FROM immigration immig\n",
    "    JOIN temperature temp ON immig.state_code=temp.state_code AND immig.year=temp.year AND immig.month=temp.month\n",
    "    JOIN demographics demo ON demo.state_code=immig.state_code\n",
    "    JOIN airports air ON air.state_code=immig.state_code\n",
    "    WHERE air.type='large_airport'\n",
    "    GROUP BY 1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20\n",
    "    ORDER BY 1,2,3,4\n",
    "\"\"\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------+----------+----------+-----------------+------------------+-----------------+------------------+------------------+-------------------+-----------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+\n",
      "|year|month|origin_country|     State|state_code|number_immigrants|   avg_temperature|       median_age|   percentage_male| percentage_female|percentage_veterans|percentage_foreign_born|     Afroamerican|             Asian|            Latino|            Native|             White|        airport_name|       x_coordinate|      y_coordinate|\n",
      "+----+-----+--------------+----------+----------+-----------------+------------------+-----------------+------------------+------------------+-------------------+-----------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+\n",
      "|2016|    1|   AFGHANISTAN|   Alabama|        AL|                2| 7.627353106898912|36.22857142857143|47.373691085135796|52.626308914864204|  6.816027377292358|      4.968803262867166|49.64306435893063|2.7408732037700942|3.7454186193407386| 0.770176891072941| 47.53298546438789|Birmingham-Shuttl...|       -86.75350189|       33.56290054|\n",
      "|2016|    1|   AFGHANISTAN|   Alabama|        AL|                2| 7.627353106898912|36.22857142857143|47.373691085135796|52.626308914864204|  6.816027377292358|      4.968803262867166|49.64306435893063|2.7408732037700942|3.7454186193407386| 0.770176891072941| 47.53298546438789|Huntsville Intern...|   -86.775100708008|   34.637199401855|\n",
      "|2016|    1|   AFGHANISTAN|   Alabama|        AL|                2| 7.627353106898912|36.22857142857143|47.373691085135796|52.626308914864204|  6.816027377292358|      4.968803262867166|49.64306435893063|2.7408732037700942|3.7454186193407386| 0.770176891072941| 47.53298546438789|Montgomery Region...|       -86.39399719|       32.30059814|\n",
      "|2016|    1|   AFGHANISTAN|   Alabama|        AL|                2| 7.627353106898912|36.22857142857143|47.373691085135796|52.626308914864204|  6.816027377292358|      4.968803262867166|49.64306435893063|2.7408732037700942|3.7454186193407386| 0.770176891072941| 47.53298546438789|Mobile Regional A...|   -88.242797851562|   30.691200256348|\n",
      "|2016|    1|   AFGHANISTAN|    Alaska|        AK|                1|-18.73249831620271|             32.2|51.204405832036024|48.795594167963976|  9.204037563400794|     11.134434791342338|7.735984867506988|12.328629538492441|  9.12670115000251|12.165921759654497| 71.20842330805671|Fairbanks Interna...|       -147.8560028|       64.81510162|\n",
      "|2016|    1|   AFGHANISTAN|    Alaska|        AK|                1|-18.73249831620271|             32.2|51.204405832036024|48.795594167963976|  9.204037563400794|     11.134434791342338|7.735984867506988|12.328629538492441|  9.12670115000251|12.165921759654497| 71.20842330805671|Ted Stevens Ancho...|-149.99600219726562|61.174400329589844|\n",
      "|2016|    1|   AFGHANISTAN|   Arizona|        AZ|                8|  5.80501084997748|          35.0375|  49.5040384110205|  50.4959615889795|  5.878487188251604|     15.164054474877664|6.583381153015129| 5.093473958016172|33.518011388714676| 2.882693394127669| 79.82170185321084| Luke Air Force Base|     -112.383003235|33.534999847399995|\n",
      "|2016|    1|   AFGHANISTAN|   Arizona|        AZ|                8|  5.80501084997748|          35.0375|  49.5040384110205|  50.4959615889795|  5.878487188251604|     15.164054474877664|6.583381153015129| 5.093473958016172|33.518011388714676| 2.882693394127669| 79.82170185321084|Phoenix Sky Harbo...|-112.01200103759766| 33.43429946899414|\n",
      "|2016|    1|   AFGHANISTAN|   Arizona|        AZ|                8|  5.80501084997748|          35.0375|  49.5040384110205|  50.4959615889795|  5.878487188251604|     15.164054474877664|6.583381153015129| 5.093473958016172|33.518011388714676| 2.882693394127669| 79.82170185321084|Tucson Internatio...|-110.94100189208984|  32.1161003112793|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Beale Air Force Base|      -121.43699646|      39.136100769|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Edwards Air Force...|        -117.884003|         34.905399|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Los Angeles Inter...|       -118.4079971|       33.94250107|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Metropolitan Oakl...|        -122.221001|         37.721298|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Ontario Internati...|-117.60099792480469|34.055999755859375|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|San Diego Interna...|     -117.190002441|     32.7336006165|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|San Francisco Int...|           -122.375| 37.61899948120117|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Norman Y. Mineta ...|        -121.929001|         37.362598|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Sacramento Intern...|-121.59100341796875| 38.69540023803711|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|John Wayne Airpor...|       -117.8679962|       33.67570114|\n",
      "|2016|    1|   AFGHANISTAN|California|        CA|               46| 6.883195351303883|36.22647058823531|49.464400385779655| 50.53559961422035|  3.739637409023924|     30.006119457942525|8.246600054950234| 18.30491417853025| 39.70784523371172|  1.61702748236879|60.046945387362896|Travis Air Force ...|   -121.92700195312|   38.262699127197|\n",
      "+----+-----+--------------+----------+----------+-----------------+------------------+-----------------+------------------+------------------+-------------------+-----------------------+-----------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table.write.mode('overwrite').parquet(\"fact_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+\n",
      "| year|month|country|state|\n",
      "+-----+-----+-------+-----+\n",
      "|false|false|  false|false|\n",
      "+-----+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_table.select(isnull('year').alias('year'),\\\n",
    "                             isnull('month').alias('month'),\\\n",
    "                             isnull('origin_country').alias('country'),\\\n",
    "                             isnull('State').alias('state')).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
